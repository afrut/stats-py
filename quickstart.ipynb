{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims to be a reference and quickstart document for basic statistical concepts aimed at engineers. All content here is taken from Montgomery and Runger - Applied Statistics and Probability for Engineers 7ed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Basic Terminology</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A <b>random experiment</b> can be thought of as executing a trial or procedure. The outcome of this trial varies with each execution even when the trial is performed in the same exact manner every time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repetitions of a random experiment will produce different outcomes. The set of all possible outcomes is called the <b>sample space</b> of the random experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A <b>discrete</b> sample space is one where the outcomes are countable (even if they are infinite). An example is the set of all ways to arrange the numbers 0 - 9. A <b>continuous</b> sample space is one where the possibilities are represented by real numbers. An example is the length of a rod (in m) or the mass of a ball (in kg)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An <b>event</b> is simply a subset of a sample space.<br>\n",
    "The <b>union</b> of two events $E_1 \\cup E_2$ is the set of all outcomes belonging to either of the two events.<br>\n",
    "The <b>intersection</b> of two events $E_1 \\cap E_2$ is the set of all outcomes common between the two events.<br>\n",
    "The <b>complement</b> of an event $'E_1$ is the set of all outcomes not in $E_1$.<br>\n",
    "Two events are <b>mutually exclusive</b> when they share no common outcomes: $E_1 \\cap E_2 = \\emptyset$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A <b>random variable</b> can be thought of as a function that produces varying values with different probabilities. For example, the random variable $X$ can be used to denote the measured length of a rod. After every measurement, it may be found that it is more likely to encounter values between $4.7 \\le X \\le 5.2$ m than it is to encounter values $X \\le 4.7$ m. Mathematically:\n",
    "<center><font size=\"4\">$P(4.7 \\le X \\le 5.2) > P(X \\le 4.7)$</font></center><br>\n",
    "The random variable $X$ can take on many varying values. The variable $x$ will be used to represent all possible values that $X$ can take."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Counting Techniques</h1><br>\n",
    "Counting techniques are useful in calculating probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Multiplication Rule</b><br>\n",
    "If there are $k$ steps, $n_1$ ways to complete step 1, $n_2$ ways to complete step 2, $n_3$ ways to complete step 3, ..., the number of different ways to complete $k$ steps is:<br>\n",
    "\n",
    "<center><font size=\"4\">\n",
    "$$N = n_1 \\times n_2 \\times n_3 \\times\\ldots\\times n_k$$\n",
    "</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Permutations</b><br>\n",
    "Permutations of $n$ unique objects can be thought of as different ways of arranging $n$ objects. For example, all the permutations of the numbers 0, 1, and 2 chosen $r=2$ at a time are:<br>\n",
    "0 1<br>\n",
    "0 2<br>\n",
    "1 0<br>\n",
    "1 2<br>\n",
    "2 0<br>\n",
    "2 1<br>\n",
    "The number of different permutations of $n$ unique objects chosen $r$ objects at a time is:<br>\n",
    "<center><font size=\"4\">$$N = P^n_r = \\frac{n!}{(n - r)!}$$</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Permutations with Similar Objects</b><br>\n",
    "There are $k$ types of objects. There are:<br>\n",
    "$n_1$ type 1 objects<br>\n",
    "$n_2$ type 2 objects<br>\n",
    "$n_3$ type 3 objects<br>\n",
    "$\\ldots$<br>\n",
    "$n_k$ type k objects<br>\n",
    "The total number of objects $n = n_1 + n_2 + n_3 +\\ldots+n_k$. The number of permutations in this case is:<br>\n",
    "<center><font size=\"4\">$$N = \\frac{n!}{n_1!n_2!n_3! \\ldots n_k!}$$</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Combinations</b><br>\n",
    "A combination is kind of like a permutation except where order doesn't matter. For example, the combination 0 1 2 is the same as 1 0 2. The number of combinations of $n$ objects chosen $r$ at a time is:<br>\n",
    "<center><font size=\"4\">$$C^n_r={n \\choose r}=\\frac{n!}{(n-r)!r!}$$</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Probability Rules</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are $N$ possible outcomes, all <b>equally likely</b> to occur, the probability of each outcome occurring is:<br>\n",
    "<center><font size=\"4\">$$P(O_n) = \\frac{1}{N}$$</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b>probability of an event $E$</b> (a subset of all possible outcomes) is the sum of all probability of outcomes belonging E. If $k$ outcomes belong to $E$, the probability of $E$ is:<br>\n",
    "<center><font size=\"4\">$$P(E)=\\sum_{i=1}^k{P(O_i)}$$</font></center><br>\n",
    "Furthermore, the probability of any event must be between 0 and 1:<br><br>\n",
    "<center><font size=\"4\">$$0 \\le P(E) \\le 1$$</font></center><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b>probability of the sample space $S$</b> must equal 1. In other words, the sum of the probabilities of all possible outcomes must equal 1.<br><br>\n",
    "<center><font size=\"4\">$$P(S)=1$$</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For two <b>mutually exclusive</b> events $E_1$ and $E_2$:<br>\n",
    "<center><font size=\"4\">\n",
    "    $$P(E_1 \\cup E_2)=P(E_1)+P(E_2)$$<br>\n",
    "    $$P(E_1 \\cap E_2)=P(\\emptyset)=0$$\n",
    "    </font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If two events $E_1$ and $E_2$ have common outcomes (have some overlap in their Venn diagram), $E_1 \\cap E_2 \\ne \\emptyset$, the <b>probability of their union</b> is:<br><br>\n",
    "<center><font size=\"4\">$$P(E_1 \\cup E_2)=P(E1)+P(E2)-P(E_1 \\cap E_2)$$</font></center><br>\n",
    "\n",
    "The intuition behind this is that if $P(E_1)$ and $P(E_2)$ were simply added, their overlap $(E_1 \\cap E_2)$ would be counted twice. So, it is appropriate to subtract the probability of their overlap $P(E_1 \\cap E_2)$ once.<br>\n",
    "\n",
    "Extending this to 3 events $E_1$, $E_2$, and $E_3$:<br><br>\n",
    "<center><font size=\"4\">\n",
    "    $$P(E_1 \\cup E_2 \\cup E_3)=P(E_1)+P(E_2)+P(E_3)-P(E_1 \\cap E_2)-P(E_1 \\cap E_3)-P(E_2 \\cap E_3)+P(E_1 \\cap E_2 \\cap E_3)$$\n",
    "    </font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of all the times $E_1$ has occurred, what proportion of these will $E_2$ also occur? This is known as <b>conditional probability</b> of $E_2$ given $E_1$: $P(E_2 \\mid E_1)$. In other words, $P(E_2 \\mid E_1)$ is the probability that $E_2$ will occur when $E_1$ has already occurred:<br><br>\n",
    "<center><font size=\"4\">$$P(E_2 \\mid E_1)=\\frac{P(E_2 \\cap E_1)}{P(E_1)}$$</font></center><br>\n",
    "\n",
    "The intution behind this is to recognize that the conditional probability $P(E_2 \\mid E_1)$ is the proportion/fraction of times that $E_2$ occurs when $E_1$ has already occurred. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability of the intersection between two events $E_1$ and $E_2$ can be expressed in terms of conditional probabilities by the <b>multiplication rule</b>:<br><br>\n",
    "<center><font size=\"4\">$$P(E_1 \\cap E_2)=P(E_1 \\mid E_2) \\times P(E_2)=P(E_2 \\mid E_1) \\times E_1$$</font></center><br>\n",
    "Intuition: The conditional probability notation $\\mid$ can \"kind of\" be treated like the divide $\\frac{x}{y}$ operator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For two mutually exclusive events $E_1$ and $E_2$, the <b>total probability rule</b> states that the probability of an event $E_1$ is:<br><br>\n",
    "<center><font size=\"4\">$$P(E_1)=P(E_1 \\cap E_2)+P(E_1 \\cap 'E_2)=P(E_1 \\mid E_2) \\times P(E_2)+P(E_1 \\mid 'E_2) \\times P('E_2)$$</font></center><br>\n",
    "This can be extended to multiple events. Say there are only 5 events in a sample space S:<br><br>\n",
    "<center><font size=\"4\">\n",
    "        \\begin{align}\n",
    "        P(E_1)&=P(E_1 \\cap E_2)+P(E_1 \\cap E_3)+P(E_1 \\cap E_4)+P(E_1 \\cap E_5)\\\\\n",
    "        &=P(E_1 \\mid E_2) \\times P(E_2)+P(E_1 \\mid E_3) \\times P(E_3)+P(E_1 \\mid E_4) \\times P(E_4)+P(E_1 \\mid E_5) \\times\n",
    "            P(E_5)\n",
    "        \\end{align}\n",
    "    </font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two events $E_1$ and $E_2$ are <b>independent</b> when the occurrence of $E_1$ does not affect the probability of $E_2$ occurring and vice versa. The following are properties of the probabilities of two independent events:<br><br>\n",
    "<center><font size=\"4\">\n",
    "$$P(E_1 \\mid E_2) = P(E_1)$$<br>\n",
    "$$P(E_1 \\cap E_2) = P(E_1)P(E_2)$$\n",
    "</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Probability Distributions</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A <b>probability mass function</b>(pmf) $f(x_i)$ characterizes the probability distribution of a <u>discrete</u> random variable. It can be thought of as a function outputs the probability of the discrete value $x_i$. It is kind of like a bar chart/histogram where the y values are probabilities instead of counts.<br>\n",
    "\n",
    "A pmf $f(x_i)$ has the following properties owing to the fact that its outputs are probabilities:<br>\n",
    "\n",
    "All probabilities are non-negative: <center><font size=\"4\">$$f(x_i) \\ge 0$$</font></center><br>\n",
    "The sum of probabilities for all $x_i$ is 1: <center><font size=\"4\">$$\\sum_{i=1}^k{f(x_i)}=1$$</font></center><br>\n",
    "The value of the pmf at each $x_i$ is the probability of $x_i$:\n",
    "<center><font size=\"4\">\n",
    "$$f(x_i)=P(X=x_i)$$\n",
    "</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A <b>probability density function</b>(pdf) $f(x)$ is a function that characterizes the probability distribution of a <u>continuous</u> random variable. It is similar to the pmf except that <b>its y values are not probabilities</b>. Instead, integrating a pdf $f(x)$ over an interval of $x$ will yield the probability of $x$ being in that range. A histogram is an approximation of the pdf.<br>\n",
    "\n",
    "A pdf $f(x)$ has the following properties:<br>\n",
    "\n",
    "All probabilities are positive: <center><font size=\"4\">$$f(x) \\ge 0$$</font></center><br>\n",
    "\n",
    "The sum of all probabilites over all values of $x$ is 1:\n",
    "<center><font size=\"4\">$$\\int_{-\\infty}^{+\\infty}{f(x)\\mathrm{d}x}$$</font></center><br>\n",
    "\n",
    "The probability of encountering $x$ in the range between $a$ and $b$ is the integral of the probability density function in that range:<br><br>\n",
    "<center><font size=\"4\">$$P(a \\le X \\le b)=\\int_a^b{f(x)\\mathrm{d}x}$$</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A <b>cumulative distribution function</b>(cdf) $F(x)$ is a function that gives the probability of encountering values of the random variable $X$ that is less than $x$. Mathematically,<br>\n",
    "<center><font size=\"4\">$$F(x)=P(X \\le x)$$</font></center><br>\n",
    "\n",
    "By definition, a cumulative distribution function involves a summation-type function.<br>\n",
    "\n",
    "For a discrete random variable $X$:\n",
    "<center><font size=\"4\">$$F(x)=\\sum_{x_i \\le x}{f(x)}$$</font></center><br>\n",
    "\n",
    "For a continuous random variable $X$:\n",
    "<center><font size=\"4\">$$F(x)=\\int_{-\\infty}^x{f(x)\\mathrm{d}x}$$</font></center><br>\n",
    "\n",
    "In either case, owing to the properties of probabilities, the value of $F(x)$ cannot be less than 0 or greater than 1:<br><br>\n",
    "<center><font size=\"4\">$$0 \\le F(x) \\le 1$$</font></center><br>\n",
    "\n",
    "Furthermore, because a cdf is a summation-type function starting from the left end of the range of x, it must be monotonically increasing:<br><br>\n",
    "<center><font size=\"4\">If $a \\le b$, then $F(a) \\le F(b)$</font></center><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b>expected value</b> of a random variable $E(X)$ can be thought of as a weighted sum of all the values of $X$ and their corresponding probabilities, $f(x)$:<br>\n",
    "\n",
    "For a discrete random variable:\n",
    "<center><font size=\"4\">$$E(X)=\\sum_{x_i}{xf(x)}$$</font></center><br>\n",
    "\n",
    "For a continuous random variable:\n",
    "<center><font size=\"4\">$$E(X)=\\int_{-\\infty}^{+\\infty}{xf(x)}$$</font></center><br>\n",
    "\n",
    "The expectation operator can be extended as follows:<br>\n",
    "\n",
    "For a discrete random variable:\n",
    "<center><font size=\"4\">$$E(h(X))=\\sum_{x_i}{h(x)f(x)}$$</font></center><br>\n",
    "\n",
    "For a continuous random variable:\n",
    "<center><font size=\"4\">$$E(h(X))=\\int_{-\\infty}^{+\\infty}{h(x)f(x)}$$</font></center><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b>mean</b> $\\mu$ and <b>variance</b> $\\sigma^2$ of a random variable $X$ can be expressed in terms of the expectation operator:<br>\n",
    "\n",
    "For a discrete random variable:\n",
    "<center><font size=\"4\">\n",
    "$$\\mu=E(X)=\\sum_{x_i}{x_if(x)}$$\n",
    "$$\\sigma^2=E((X-\\mu)^2)=\\sum_{x_i}{(x_i-\\mu)^2f(x)}$$\n",
    "</font></center><br>\n",
    "\n",
    "For a continuous random variable:\n",
    "<center><font size=\"4\">\n",
    "$$\\mu=E(X)=\\int_{-\\infty}^{+\\infty}{xf(x)}$$\n",
    "$$\\sigma^2=E((X-\\mu)^2)=\\int_{-\\infty}^{+\\infty}{(x-\\mu)^2f(x)}$$\n",
    "</font></center><br>\n",
    "\n",
    "The <b>standard deviation</b> of a random variable X is the square root of the variance X:<br>\n",
    "<center><font size=\"4\">\n",
    "$$\\sigma=\\sqrt{\\sigma^2}$$\n",
    "</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Bernoulli Trial</h2>\n",
    "\n",
    "A <b>Bernoulli trial</b> is a random experiment with only two outcomes, 0 or 1. The probability of obtaining 0 or 1 may not be equal. For example, the probability of obtaining tails when flipping a (very) unfair coin could be 0.8, and the probability of obtaining heads is necessarily 0.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Binomial Distribution</h2>\n",
    "\n",
    "The <b>Binomial Distribution</b> of a discrete random variable $X$ gives the probability of encountering $x$ successful outcomes in $n$ independent Bernoulli trials of constant probability $p$. For example, take a coin that has a probability of landing tails 1/10 times. If the coin is flipped 20 times, what is the probability of getting exactly $x=5$ tails? Here, $n=20$, $p=0.1$, and $x=5$.<br>\n",
    "\n",
    "Mathematically, the Binomial Distribution is:\n",
    "<center><font size=\"4\">\n",
    "$$f(x)={n \\choose x}p^x(1-p)^{n-x}$$<br>\n",
    "$$x=0, 1, 2, \\ldots, n$$\n",
    "</font></center><br>\n",
    "\n",
    "The mean and variance of the Binomial Distribution are:\n",
    "<center><font size=\"4\">\n",
    "$$\\mu=E(X)=np$$<br>\n",
    "$$\\sigma^2=V(X)=np(1-p)$$\n",
    "</font></center><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Geometric Distribution</h2>\n",
    "\n",
    "The <b>Geometric Distribution</b> of a discrete random variable $X$ gives the probability of encountering the first success after performing $x$ independent Bernoulli trials of constant probability $p$. So, it answers the question, \"What is the probability of obtaining the first tail after 10 coin flips, if the coin has a probability of coming up tails 2/10 times?\" Here, $x=10$, and $p$ is 0.2.<br>\n",
    "\n",
    "Mathematically, the Geometric Distribution is:<br>\n",
    "<center><font size=\"4\">\n",
    "$$f(x)=(1-p)^{x-1}p$$<br>\n",
    "$$x=1,2, \\ldots$$\n",
    "</font></center><br>\n",
    "\n",
    "The mean and variance of the Geometric Distribution are:\n",
    "<center><font size=\"4\">\n",
    "$$\\mu=E(X)=\\frac{1}{p}$$<br>\n",
    "$$\\sigma^2=V(X)=\\frac{1-p}{p^2}$$\n",
    "</font></center><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Negative Binomial Distribution</h2>\n",
    "\n",
    "The <b>Negative Binomial Distribution</b> of a discrete random variable $X$ gives the probability of performing $x$ independent Bernoulli trials of constant probability $p$ until $r$ successes are encountered. It answers the question, \"If a coin is to be flipped until 5 tails are encountered, what is the probability that 20 flips will be executed when the coin comes up tails 2/10 times?\" Here, $r=5$, $x=20$, and $p=0.2$.<br>\n",
    "\n",
    "Mathematically, the Negative Binomial Distribution is:\n",
    "<center><font size=\"4\">\n",
    "$$f(x)={x-1 \\choose r-1}(1-p)^{x-r}p^r$$<br>\n",
    "$$x=r, r+1, r+2, \\ldots$$\n",
    "</font></center><br>\n",
    "\n",
    "The mean and variance of the Binomial Distribution are:\n",
    "<center><font size=\"4\">\n",
    "$$\\mu=E(X)=\\frac{r}{p}$$<br>\n",
    "$$\\sigma^2=V(X)=\\frac{r(1-p)}{p^2}$$\n",
    "</font></center><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Hypergeometric Distribution</h2>\n",
    "\n",
    "The <b>Hypergeometric Distribution</b> of a discrete random variable $X$ helps in the following situation. There are 100 balls in a bag. 27 of these balls are blue. If 3 balls are taken from the bag, without replacement, what is the probability of obtaining 2 blue balls? In general terms, there are $N$ objects, $K$ of which are designated as successes. If a sample of size $n$ is drawn from the $N$ objects, what is the probability that the sample contains $x$ successes? Here, $N=100$, $K=27$, $n=3$, and $x=2$.<br>\n",
    "\n",
    "Mathematically, the Hypergeometric Distribution is:\n",
    "<center><font size=\"4\">\n",
    "$$f(x)=\\frac{{K \\choose x}{N-K \\choose n-x}}{N \\choose n}$$<br>\n",
    "$x=$max$\\{0,n+K-N\\}$ to min$\\{K,n\\}$\n",
    "</font></center><br>\n",
    "\n",
    "The mean and variance of the Hypergeometric Distribution are:\n",
    "<center><font size=\"4\">\n",
    "$$\\mu=E(X)=np$$<br>\n",
    "$$\\sigma^2=V(X)=np(1 - p)\\left( \\frac{N - n}{N - 1} \\right)$$<br>\n",
    "$$p = \\frac{K}{N}$$\n",
    "</font></center><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Poisson Distribution</h2>\n",
    "\n",
    "The <b>Poisson Distribution</b> of a discrete random variable $X$ helps in the following situation. Suppose that a length of wire has 2.3 flaws per mm. What is the probability of having 5 flaws in 10 mm of wire? This is called a <b>Poisson process</b>. When an average number of successes per unit $\\lambda$ is given, the Poisson Distribution gives the probability of encountering $x$ successes in $T$ units. In the example above, $\\lambda=2.3$, $T=10$, and $x=5$.<br>\n",
    "\n",
    "Mathematically, the Poisson Distribution is:\n",
    "<center><font size=\"4\">\n",
    "$$f(x)=\\frac{e^{-\\lambda T}(\\lambda T)^x}{x!}$$<br>\n",
    "$$x=0, 1, 2, \\ldots$$\n",
    "</font></center><br>\n",
    "\n",
    "The mean and variance of the Poisson Distribution are:\n",
    "<center><font size=\"4\">\n",
    "$$\\mu=E(X)=\\lambda T$$<br>\n",
    "$$\\sigma^2=V(X)=\\lambda T$$\n",
    "</font></center><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Normal Distribution</h2>\n",
    "\n",
    "Suppose that there are a million balls. Take a sample of 10 balls, measure their diameters, average them and call this average a1. Take another sample of 10, measure, average, and call this a2. Take yet another sample of 10, measure, average, and call this a3. Keep repeating this (many) $n$ times to get $a_n$. If a histogram is made out of the values of $a_n$, the <b>Central Limit Theorem</b> states that this histogram will be approximate the <b>Normal Distribution</b>. In other words, the continuous random varialbe $X$, which are the averages of diameters of samples of size $n=10$, will be normally distributed.<br>\n",
    "\n",
    "Mathematically, the Normal Distribution with mean $\\mu$ and variance $\\sigma^2$ is:\n",
    "<center><font size=\"4\">\n",
    "$$f(x)=\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{\\frac{-(x-\\mu)^2}{2\\sigma^2}}$$<br>\n",
    "$$x=0, 1, 2, \\ldots$$\n",
    "</font></center><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Standard Normal Distribution</h2>\n",
    "\n",
    "The <b>Standard Normal Distribution</b> is obtained by modifying the normal distribution by <b>standardization</b>. Given a continuous random variable $X$, the standardized random variable $Z$ can be obtained by mean-centering and scaling by the standard deviation:<br><br>\n",
    "<center><font size=\"4\">\n",
    "$$Z=\\frac{(X-\\mu)}{\\sigma}$$\n",
    "</font></center><br>\n",
    "\n",
    "The continuous standard normal random varialbe $Z$ will be normall distributed with:<br>\n",
    "<center><font size=\"4\">\n",
    "$$\\mu=0$$<br>\n",
    "$$\\sigma^2=1$$\n",
    "</font></center><br>\n",
    "\n",
    "The standard normal distribution is usefully in calculating probabilities. Calculating probabilities of normal variables involves the integration of many normal distributions with many different means and variances. Instead, it is more convenient to standardize the random variables and only integrate the standard normal distribution to calculate probabilities:\n",
    "<center><font size=\"4\">\n",
    "$$P(X \\le x)=P(Z \\le z)=P\\left(\\frac{X-\\mu}{\\sigma} \\le \\frac{x-\\mu}{\\sigma} \\right)$$<br>\n",
    "</font></center><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Standard Normal Approximation to the Binomial Distribution</h2>\n",
    "\n",
    "It is sometimes convenient to approximate a binomial random variable with a standard normal variable for the purposes of <b>calculating probabilities</b>. Given $X$ is a binomial random variable with parameters $n$ and $p$, the standard normal variable $Z$ is calculated as follows:<br><br>\n",
    "<center><font size=\"4\">\n",
    "$$Z=\\frac{X-np}{\\sqrt{np(1-p)}}$$\n",
    "</font></center><br>\n",
    "\n",
    "Approximating probabilities can be computed as follows:<br>\n",
    "<center><font size=\"4\">\n",
    "$$P(X \\le x)=P(X \\le x+0.5)\\approx P\\left(Z \\le \\frac{x+0.5-np}{\\sqrt{np(1-p)}} \\right)$$\n",
    "$$P(X \\ge x)=P(X \\ge x-0.5)\\approx P\\left(Z \\ge \\frac{x-0.5-np}{\\sqrt{np(1-p)}} \\right)$$\n",
    "</font></center><br>\n",
    "\n",
    "These approximations are good when:\n",
    "<center><font size=\"4\">\n",
    "$$np \\gt 5$$<br>\n",
    "$$n(1-p) \\gt 5$$\n",
    "</font></center><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Exponential Distribution</h2>\n",
    "\n",
    "Given a Poisson process with a mean number of successes per unit $\\lambda$, the <b>Exponential Distribution</b> gives the probability of having a distance $x$ between two instances of successes. Suppose that a length of wire has 2.3 flaws per mm. What is the probability of having no flaws in 10 mm of wire? Here, $\\lambda=2.3$, and $x=10$.<br>\n",
    "\n",
    "Mathematically, the exponential distribution is:\n",
    "<center><font size=\"4\">\n",
    "$$f(x)=\\lambda e^{-\\lambda x}$$<br>\n",
    "$$0 \\le x \\le \\infty$$\n",
    "</font></center><br>\n",
    "\n",
    "The mean and variance of the exponential distribution are:\n",
    "<center><font size=\"4\">\n",
    "$$\\mu=E(X)=\\frac{1}{\\lambda}$$<br>\n",
    "$$\\sigma^2=V(X)=\\frac{1}{\\lambda^2}$$\n",
    "</font></center><br>\n",
    "\n",
    "The exponential distribution has a property called <b>lack of memory</b>. Using the example, suppose that a flaw has not been encountered in 60 mm of wire. What is the probability that a flaw will be encountered in the next 10 mm (or in 70 mm of wire)? It might be tempting to assume that because there were no flaws in 60 mm of wire, it is \"overdue\" for a flaw. However, the probability of encountering a flaw in the next 10 mm of wire <b>independent of the past</b>. That is, it is independent of the fact that a flaw has not been encountered in the last 60 mm. Mathematically, <br><br>\n",
    "<center><font size=\"4\">\n",
    "$$P(X<t+a|X>t)=P(X<a)$$\n",
    "</font></center><br>\n",
    "\n",
    "Here, $t=60$ mm, and $a=10$ mm, making $t+a=70$ mm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Joint Probability Distributions</h1>\n",
    "\n",
    "<b>Joint probability distributions</b> can be thought of as a function that gives the probability of encountering different values of two random variables together. For two random continuous variables, their <b>joint probability density function</b>  (joint pdf) $f_{XY}(x, y)$ is a surface; the x and y-axes are different values of the random variables; the z-axis is the probability of encountering the specific $(X=x, Y=y)$ pair.<br>\n",
    "\n",
    "Joint pdf's have the following properties owing to the basic properties of probabilities:<br>\n",
    "\n",
    "The probability of any combination of x and y values $(X=x, Y=y)$ must be non-negative:<br><br>\n",
    "<center><font size=\"4\">\n",
    "$$f_{XY}(x, y) \\ge 0$$\n",
    "</font></center><br>\n",
    "\n",
    "The sum of all probabilities in the applicable range must be 1:<br><br>\n",
    "<center><font size=\"4\">\n",
    "$$\\int_{-\\infty}^{+\\infty}{\\int_{-\\infty}^{+\\infty}{f_{XY}(x, y)\\mathrm{d}x\\mathrm{d}y}}=1$$\n",
    "</font></center><br>\n",
    "\n",
    "Combinations of $(x, y)$ value pairs are represented by a region in the x-y plane. The region is defined by an interval of X and an interval of Y. When double-integrating, <b>try to always integrate the variable with largest interval first</b>. This prevents accidentally including regions of the x-y plane that are not desired. Failing that, split up the integral based on different regions of the x-y plane.\n",
    "<center><font size=\"4\">\n",
    "$$P((X,Y)\\in R)=\\int{\\int_{R}{f_{XY}(x, y)\\mathrm{d}x\\mathrm{d}y}}$$\n",
    "</font></center><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b>marginal probability density function</b> of X can be obtained from the joint pdf of X and Y by integrating Y out over the relevant region R. This yields the pdf of X. A similar process can be used to obtain the marginal pdf of Y.<br>\n",
    "<center><font size=\"4\">\n",
    "$$f_X(x)=\\int_{R}{f_{XY}(x, y)\\mathrm{d}y}$$<br>\n",
    "$$f_Y(y)=\\int_{R}{f_{XY}(x, y)\\mathrm{d}x}$$\n",
    "</font></center><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b>mean</b> and <b>variance</b> of a random variable $X$ from a joint pdf can be expressed with its marginal pdf and the expectation operator:<br>\n",
    "<center><font size=\"4\">\n",
    "$$E(x)=\\int_{-\\infty}^{+\\infty}{xf_X(x)\\mathrm{d}x}=\\int_{-\\infty}^{+\\infty}{\\int_{-\\infty}^{+\\infty}{xf_{XY}(x, y)\\mathrm{d}x\\mathrm{d}y}}$$<br>\n",
    "$$V(x)=\\int_{-\\infty}^{+\\infty}{(x-\\mu)^2f_X(x)\\mathrm{d}x}=\\int_{-\\infty}^{+\\infty}{\\int_{-\\infty}^{+\\infty}{(x-\\mu)^2f_{XY}(x, y)\\mathrm{d}x\\mathrm{d}y}}$$<br>\n",
    "</font></center><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Covariance and Correlation</h1>\n",
    "\n",
    "The <b>covariance</b> between two random variables X and Y is a measure of their <b>linear</b> relationship. The <b>correlation</b> scales the covariance by the standard deviation of each variable. Two random variables are said to be correlated when their correlation is non-zero.<br>\n",
    "\n",
    "The covariance between two random variables $\\sigma_{XY}$ is defined mathematically as:<br><br>\n",
    "<center><font size=\"4\">\n",
    "$$\\sigma_{XY}=E[(X-\\mu_X)(Y-\\mu_Y)]=E(XY)-\\mu_X\\mu_Y$$\n",
    "</font></center><br>\n",
    "\n",
    "The correlation between two random variables $\\rho_{XY}$ is defined mathematically as:<br><br>\n",
    "<center><font size=\"4\">\n",
    "$$\\rho_{XY}=\\frac{\\sigma_{XY}}{\\sigma_X \\sigma_Y}$$<br>\n",
    "$$-1 \\le \\rho_{XY} \\le +1$$\n",
    "</font></center><br>\n",
    "\n",
    "The covariance and correlation of two independent variables is 0. But, two variables whose covariance and correlation are zero are <b>not necessarily independent</b>.<br>\n",
    "<center><font size=\"4\">\n",
    "$$\\sigma_{XY}=\\rho_{XY}=0$$\n",
    "</font></center><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Linear Functions of Random Variables</h1>\n",
    "\n",
    "This section details how to calculate the mean and variance of a random variable $Y$ that is a linear function of random variables $X_i$:<br><br>\n",
    "<font size=\"4\">\n",
    "    $$Y = c_0 + c_1X_1 + c_2X_2 + \\ldots + c_iX_i$$\n",
    "</font>\n",
    "\n",
    "The <b>mean</b> and <b>variance</b> of $Y$ can be expressed in terms of the mean and variance of the individual random variables $X_i$:<br><br>\n",
    "<font size=\"4\">\n",
    "    $$E(Y) = c_0 + c_1E(X_1) + c_2E(X_2) + \\ldots + c_iE(X_i)$$<br>\n",
    "    $$V(Y) = c_1^2V(X_1) + c_2^2V(X_2) + \\ldots + c_i^2V(X_i) + 2 \\sum_{a<b}{\\sum{c_ac_b\\mathrm{cov}(X_a, X_b)}}$$\n",
    "</font>\n",
    "\n",
    "If all $X_i$ are independent, the variance of $Y$ can be simplified to:<br><br>\n",
    "<font size=\"4\">\n",
    "    $$V(Y) = c_1^2V(X_1) + c_2^2V(X_2) + \\ldots + c_i^2V(X_i)$$\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Mean and Variance of an Average</h2>\n",
    "\n",
    "Sometimes, multiple samples of $X$ can be taken from a pool where $E(X)=\\mu$ and $V(X)=\\sigma^2$. The sample averages $\\overline{X}$ can be calculated as in:<br><br>\n",
    "<font size=\"4\">\n",
    "    $$S_1=\\{x_1, x_2, x_3, \\ldots, x_i\\} \\;\\;\\;\\; \\overline{X}_1=\\frac{1}{i}\\sum_1^i{x_i}$$<br>\n",
    "    $$S_2=\\{x_1, x_2, x_3, \\ldots, x_i\\} \\;\\;\\;\\; \\overline{X}_2=\\frac{1}{i}\\sum_1^i{x_i}$$<br>\n",
    "    $$S_3=\\{x_1, x_2, x_3, \\ldots, x_i\\} \\;\\;\\;\\; \\overline{X}_3=\\frac{1}{i}\\sum_1^i{x_i}$$<br>\n",
    "    $$S_p=\\{x_1, x_2, x_3, \\ldots, x_i\\} \\;\\;\\;\\; \\overline{X}_p=\\frac{1}{i}\\sum_1^i{x_i}$$<br>\n",
    "</font><br>\n",
    "\n",
    "The mean and variance of all $\\overline{X}_p$ is:\n",
    "<font size=\"4\">\n",
    "    $$E(\\overline{X}_p)=\\mu$$<br>\n",
    "    $$V(\\overline{X}_p)=\\frac{\\sigma^2}{p}$$<br>\n",
    "</font><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
